name: ðŸ”§ Manual Test Run

# ============================================
# MANUAL TEST EXECUTION
# 
# Use this workflow to:
# - Run tests against any environment
# - Test specific roles
# - Debug failing tests
# ============================================

on:
  workflow_dispatch:
    inputs:
      target_url:
        description: 'URL to test against'
        required: true
        type: choice
        options:
          - 'https://amsf001-project-tracker.vercel.app'
          - 'staging'
          - 'custom'
        default: 'https://amsf001-project-tracker.vercel.app'
      
      custom_url:
        description: 'Custom URL (only if "custom" selected above)'
        required: false
        type: string
      
      test_type:
        description: 'Test type to run'
        required: true
        type: choice
        options:
          - 'all'
          - 'unit-only'
          - 'e2e-only'
          - 'smoke'
        default: 'all'
      
      role:
        description: 'Role to test (E2E only)'
        required: false
        type: choice
        options:
          - 'all'
          - 'admin'
          - 'supplier-pm'
          - 'supplier-finance'
          - 'customer-pm'
          - 'customer-finance'
          - 'contributor'
          - 'viewer'
        default: 'all'
      
      debug_mode:
        description: 'Enable debug mode (verbose output)'
        required: false
        type: boolean
        default: false

env:
  VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
  VITE_SUPABASE_ANON_KEY: ${{ secrets.VITE_SUPABASE_ANON_KEY }}
  E2E_TEST_PASSWORD: ${{ secrets.E2E_TEST_PASSWORD }}

jobs:
  # ============================================
  # DETERMINE TARGET URL
  # ============================================
  setup:
    name: ðŸ”§ Setup
    runs-on: ubuntu-latest
    outputs:
      target_url: ${{ steps.url.outputs.url }}
      run_unit: ${{ steps.tests.outputs.run_unit }}
      run_e2e: ${{ steps.tests.outputs.run_e2e }}
    
    steps:
      - name: Determine target URL
        id: url
        run: |
          if [ "${{ github.event.inputs.target_url }}" == "custom" ]; then
            echo "url=${{ github.event.inputs.custom_url }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.inputs.target_url }}" == "staging" ]; then
            echo "url=https://amsf001-project-tracker-staging.vercel.app" >> $GITHUB_OUTPUT
          else
            echo "url=${{ github.event.inputs.target_url }}" >> $GITHUB_OUTPUT
          fi

      - name: Determine test types
        id: tests
        run: |
          TYPE="${{ github.event.inputs.test_type }}"
          if [ "$TYPE" == "all" ] || [ "$TYPE" == "unit-only" ]; then
            echo "run_unit=true" >> $GITHUB_OUTPUT
          else
            echo "run_unit=false" >> $GITHUB_OUTPUT
          fi
          
          if [ "$TYPE" == "all" ] || [ "$TYPE" == "e2e-only" ] || [ "$TYPE" == "smoke" ]; then
            echo "run_e2e=true" >> $GITHUB_OUTPUT
          else
            echo "run_e2e=false" >> $GITHUB_OUTPUT
          fi

      - name: Display configuration
        run: |
          echo "ðŸŽ¯ Target URL: ${{ steps.url.outputs.url }}"
          echo "ðŸ§ª Test Type: ${{ github.event.inputs.test_type }}"
          echo "ðŸ‘¤ Role: ${{ github.event.inputs.role }}"
          echo "ðŸ› Debug: ${{ github.event.inputs.debug_mode }}"

  # ============================================
  # UNIT TESTS
  # ============================================
  unit-tests:
    name: ðŸ”¬ Unit Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.run_unit == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests
        run: npm run test:ci
        env:
          NODE_ENV: development
          DEBUG: ${{ github.event.inputs.debug_mode == 'true' && '*' || '' }}

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: manual-coverage-${{ github.run_id }}
          path: coverage/
          retention-days: 7

  # ============================================
  # E2E TESTS
  # ============================================
  e2e-tests:
    name: ðŸŽ­ E2E Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.run_e2e == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Run E2E tests
        run: |
          ROLE="${{ github.event.inputs.role }}"
          TYPE="${{ github.event.inputs.test_type }}"
          
          if [ "$TYPE" == "smoke" ]; then
            npx playwright test --project=admin --grep="@smoke|@critical"
          elif [ "$ROLE" == "all" ]; then
            npx playwright test
          else
            npx playwright test --project=$ROLE
          fi
        env:
          PLAYWRIGHT_BASE_URL: ${{ needs.setup.outputs.target_url }}
          CI: true
          DEBUG: ${{ github.event.inputs.debug_mode == 'true' && 'pw:*' || '' }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: manual-playwright-${{ github.run_id }}
          path: playwright-report/
          retention-days: 14

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: manual-screenshots-${{ github.run_id }}
          path: test-results/
          retention-days: 7

  # ============================================
  # SUMMARY
  # ============================================
  summary:
    name: ðŸ“Š Summary
    runs-on: ubuntu-latest
    needs: [setup, unit-tests, e2e-tests]
    if: always()
    
    steps:
      - name: Create summary
        run: |
          echo "## ðŸ”§ Manual Test Run Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Configuration:**" >> $GITHUB_STEP_SUMMARY
          echo "- Target: \`${{ needs.setup.outputs.target_url }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Type: ${{ github.event.inputs.test_type }}" >> $GITHUB_STEP_SUMMARY
          echo "- Role: ${{ github.event.inputs.role }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.setup.outputs.run_unit }}" == "true" ]; then
            echo "| Unit Tests | ${{ needs.unit-tests.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "${{ needs.setup.outputs.run_e2e }}" == "true" ]; then
            echo "| E2E Tests | ${{ needs.e2e-tests.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          fi
