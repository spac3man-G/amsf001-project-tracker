# Evaluator Tool - Implementation Plan

## Document Purpose

This document serves as the **master implementation guide** for the Evaluator tool. It is designed to:

1. **Provide full context** for any AI assistant session to understand the project
2. **Track progress** through clearly defined checkpoints
3. **Enable multi-session work** by maintaining state between chat sessions
4. **Define stopping points** where the AI should check in before proceeding

**Usage:** At the start of any new AI session, share this document along with `APPLICATION-CONTEXT.md` and `LOCAL-ENV-SETUP.md` to provide complete context.

---

## Progress Tracker

### Current Status

| Phase | Status | Last Updated | Notes |
|-------|--------|--------------|-------|
| Phase 0: Documentation | ‚úÖ COMPLETE | 2026-01-01 | Architecture doc created |
| Phase 1: Database Foundation | ‚úÖ COMPLETE | 2026-01-01 | All 18 migrations created and pushed |
| Phase 2: Core Infrastructure | ‚úÖ COMPLETE | 2026-01-01 | Context, hooks, services, routing, navigation |
| Phase 3: Requirements Module | ‚úÖ COMPLETE | 2026-01-01 | Sessions 3A, 3B, 3C all complete |
| Phase 4: Input Capture | ‚úÖ COMPLETE | 2026-01-01 | Sessions 4A, 4B, 4C all complete |
| Phase 5: Vendor Management | ‚úÖ COMPLETE | 2026-01-03 | Sessions 5A, 5B all complete |
| Phase 6: Evaluation & Scoring | ‚úÖ COMPLETE | 2026-01-04 | Sessions 6A, 6B, 6C all complete |
| Phase 7: Traceability & Reports | üîÑ IN PROGRESS | 2026-01-04 | Session 7A complete, 7B pending |
| Phase 8: AI Features | üî≤ NOT STARTED | - | - |
| Phase 9: Portals | üî≤ NOT STARTED | - | - |
| Phase 10: Testing & Polish | üî≤ NOT STARTED | - | - |

**Legend:** ‚úÖ Complete | üîÑ In Progress | üî≤ Not Started | ‚è∏Ô∏è Blocked

### Last Checkpoint Completed

```
Checkpoint: PHASE-6-COMPLETE
Date: 2026-01-04
Summary: Phase 6 (Evaluation & Scoring) fully complete. All sessions implemented:
         - Session 6A: Evidence Management (complete)
         - Session 6B: Scoring Interface (complete)
         - Session 6C: Reconciliation (complete)
         
Session 6A implemented:
  - evidence.service.js with full CRUD, linking, coverage reports
  - Evidence types: demo_note, reference_check, document_excerpt, vendor_response,
    meeting_note, technical_review, pricing_analysis, poc_result
  - Evidence sentiment tracking (positive, neutral, negative, mixed)
  - EvidenceCard component
  - EvidenceForm component with linking to requirements/criteria
  
Session 6B implemented:
  - scores.service.js with individual scoring, consensus, weighted calculations
  - EvaluationHub page with overview, scoring, reconciliation, evidence views
  - ScoringInterface component with star rating, rationale, evidence linking
  - ScoreCard component for displaying scores
  - Score submission workflow
  
Session 6C implemented:
  - ReconciliationPanel component showing evaluator variance
  - Consensus score entry with rationale
  - calculateWeightedTotal() for vendor ranking
  - Score comparison across evaluators
  - Vendor ranking by weighted scores

Files Created:
  - src/services/evaluator/evidence.service.js (747 lines)
  - src/services/evaluator/scores.service.js (832 lines)
  - src/components/evaluator/scoring/EvidenceCard.jsx + CSS
  - src/components/evaluator/scoring/EvidenceForm.jsx + CSS
  - src/components/evaluator/scoring/ScoringInterface.jsx + CSS
  - src/components/evaluator/scoring/ScoreCard.jsx + CSS
  - src/components/evaluator/scoring/ReconciliationPanel.jsx + CSS
  - src/components/evaluator/scoring/index.js
  - src/pages/evaluator/EvaluationHub.jsx + CSS
  
Files Modified:
  - src/services/evaluator/index.js (added evidence and scores exports)
  - src/components/evaluator/index.js (added scoring components)
  - src/App.jsx (added EvaluationHub import and route)
  - docs/EVALUATOR-IMPLEMENTATION-PLAN.md (updated progress)
  
Build Status: ‚úÖ Passing (pending verification)
Next Action: Phase 7 - Traceability & Reports
```
```
  - src/components/evaluator/documents/index.js
  - src/pages/evaluator/DocumentsHub.jsx
  - src/pages/evaluator/DocumentsHub.css
  - supabase/migrations/202601010019_create_evaluation_documents_storage.sql
Files Modified:
  - src/services/evaluator/index.js (added documents exports)
  - src/components/evaluator/index.js (added documents components)
  - src/App.jsx (added DocumentsHub import and route)
  - src/pages/evaluator/EvaluatorDashboard.jsx (added Documents quick action)
Build Status: ‚úÖ Passing (pending verification)
Next Action: Phase 5 - Vendor Management
```

---

## Part 1: Project Context

### 1.1 Business Context

**Client Engagement:** Smart Consulting has been engaged by Carey Olsen (law firm) to replace their ViewPoint CSP (Corporate Service Provider) platform. This is a 5-phase consulting project running January to June 2025.

**The Need:** During this engagement, Smart Consulting identified a gap in their tooling. They need a structured way to:
- Gather and trace requirements back to stakeholders
- Evaluate multiple vendors against weighted criteria
- Maintain full audit trails of decisions
- Provide clients with visibility into the process
- Generate professional reports and traceability matrices

**The Solution:** Build "Evaluator" - a new tool within the existing AMSF001 Project Tracker application that handles technology procurement evaluations with full traceability.

### 1.2 Product Vision

**Evaluator** is a multi-tenant vendor evaluation platform designed for consultancy use. It provides:

1. **Workshop-Centric Input Capture** - Requirements gathered in facilitated sessions, validated post-workshop
2. **Full Traceability** - Every score traceable to evidence, requirements, workshops, and stakeholders
3. **Weighted Evaluation** - Configurable categories and criteria with percentage weights
4. **Multi-Stakeholder Perspectives** - Different specialist areas (CSP Ops, IT, Finance, Compliance)
5. **Client Portal** - Branded dashboards for client visibility
6. **Vendor Portal** - Light-touch interface for vendor responses
7. **AI Assistance** - Gap analysis, market research, document parsing

### 1.3 Key Differentiators

Compared to existing tools (Olive.app, procurement suites):
- **Workshop-centric** not survey-first
- **Consultant-led multi-client** not single-company focused
- **Deep provenance tracking** with full audit trails
- **Interactive client experience** not just PDF reports
- **Lightweight vendor portal** without complex procurement workflows

### 1.4 User Roles

| Role | Description | Key Actions |
|------|-------------|-------------|
| **Consultant Admin** | Smart Consulting team lead | Full access, configure projects, manage users |
| **Consultant Evaluator** | Smart Consulting team member | Capture requirements, score vendors, collect evidence |
| **Client Stakeholder** | Carey Olsen project team | View progress, approve requirements, participate in workshops |
| **Workshop Participant** | Anyone invited to workshop | Complete follow-up forms, validate attributed requirements |
| **Vendor** | Vendor sales/presales team | Respond to questions, upload materials (portal only) |

---

## Part 2: Technical Context

### 2.1 Existing Application

Evaluator is being built within the **AMSF001 Project Tracker** application. Key facts:

- **Stack:** React 18 + Vite, Supabase (PostgreSQL + Auth + RLS), Vercel (hosting + serverless)
- **Multi-tenancy:** Organisation ‚Üí Project ‚Üí Entity hierarchy with Row Level Security
- **Patterns:** BaseService for data access, React Context for state, custom hooks for permissions
- **AI Integration:** Claude API for chat assistant, receipt scanning
- **Existing Tools:** Tracker (timesheets, expenses, milestones), Planner (project planning), Estimator (cost estimation), Benchmarking (SFIA rates)

**Key Files to Reference:**
- `docs/APPLICATION-CONTEXT.md` - Full application architecture
- `docs/LOCAL-ENV-SETUP.md` - Development environment setup
- `docs/EVALUATOR-TECHNICAL-ARCHITECTURE.md` - Detailed technical design

### 2.2 Development Environment

```
Location: ~/Projects/amsf001-project-tracker/
Repository: github.com/spac3man-G/amsf001-project-tracker
Database: Supabase project ljqpmrcqxzgcfojrkxce
Deployment: Vercel (auto-deploy from GitHub)

Key Commands:
  npm run dev          # Start dev server (localhost:5173)
  npm run build        # Production build
  supabase db push     # Push migrations to database
  supabase migration new <name>  # Create new migration
```

### 2.3 Architecture Decision: Parallel Not Nested

Evaluator sits **parallel** to the existing Project structure:

```
Organisation
‚îú‚îÄ‚îÄ Project (existing - delivery tracking)
‚îÇ   ‚îî‚îÄ‚îÄ Milestones, Deliverables, Timesheets, etc.
‚îÇ
‚îî‚îÄ‚îÄ EvaluationProject (new - vendor evaluation)
    ‚îî‚îÄ‚îÄ Requirements, Vendors, Scores, etc.
```

This means:
- Completely separate data model
- Independent permission system
- No coupling to delivery project lifecycle
- Future option to link evaluation outcomes to delivery projects

### 2.4 Key Technical Patterns to Follow

**Services:** Extend `BaseService`, use `evaluation_project_id` for scoping
**Contexts:** Follow `ProjectContext` pattern for `EvaluationContext`
**Hooks:** Follow `usePermissions` pattern for `useEvaluatorPermissions`
**Components:** Reuse common components, new components in `src/components/evaluator/`
**Pages:** New pages in `src/pages/evaluator/`
**API:** New endpoints in `api/evaluator/`

---

## Part 3: Data Model Summary

### 3.1 Core Tables

| Table | Purpose | Key Fields |
|-------|---------|------------|
| `evaluation_projects` | Main container | name, organisation_id, status, client_name |
| `evaluation_project_users` | Access control | user_id, role, stakeholder_area_id |
| `stakeholder_areas` | Departments/functions | name, evaluation_project_id |
| `evaluation_categories` | Scoring categories | name, weight, evaluation_project_id |
| `scoring_scales` | Score definitions | value (1-5), label, description |

### 3.2 Input Tables

| Table | Purpose | Key Fields |
|-------|---------|------------|
| `workshops` | Workshop sessions | name, scheduled_date, facilitator_id, status |
| `workshop_attendees` | Who attended | user_id, stakeholder_area_id, attended |
| `surveys` | Forms/questionnaires | name, type, questions (JSONB) |
| `survey_responses` | Form submissions | respondent_id, answers (JSONB) |
| `evaluation_documents` | Uploaded files | name, file_url, parse_results |

### 3.3 Requirements Tables

| Table | Purpose | Key Fields |
|-------|---------|------------|
| `requirements` | Core requirements | reference_code, title, category_id, priority, status, source_* |
| `evaluation_criteria` | Scoring criteria | name, category_id, weight |
| `requirement_criteria` | Links reqs to criteria | requirement_id, criterion_id |

### 3.4 Vendor Tables

| Table | Purpose | Key Fields |
|-------|---------|------------|
| `vendors` | Vendor records | name, status, portal_access_code |
| `vendor_contacts` | Vendor people | vendor_id, name, email, is_primary |
| `vendor_questions` | RFP questions | question_text, question_type |
| `vendor_responses` | Vendor answers | vendor_id, question_id, response_text |
| `vendor_documents` | Uploaded materials | vendor_id, document_type, file_url |

### 3.5 Evaluation Tables

| Table | Purpose | Key Fields |
|-------|---------|------------|
| `evidence` | Supporting evidence | vendor_id, type, title, content |
| `evidence_links` | Links to reqs/criteria | evidence_id, requirement_id |
| `scores` | Individual evaluator scores | vendor_id, criterion_id, evaluator_id, score_value |
| `consensus_scores` | Reconciled scores | vendor_id, criterion_id, consensus_value |

### 3.6 Supporting Tables

| Table | Purpose |
|-------|---------|
| `ai_tasks` | Track AI operations |
| `evaluation_audit_log` | Full audit trail |

**Full schema details:** See `docs/EVALUATOR-TECHNICAL-ARCHITECTURE.md`

---

## Part 4: Implementation Phases


### Phase 1: Database Foundation

**Objective:** Create all database tables and RLS policies

**Estimated Effort:** 1-2 sessions

#### Tasks

- [x] **1.1** Create migration: `evaluation_projects` table
- [x] **1.2** Create migration: `evaluation_project_users` table  
- [x] **1.3** Create migration: `stakeholder_areas` table
- [x] **1.4** Create migration: `evaluation_categories` table
- [x] **1.5** Create migration: `scoring_scales` table
- [x] **1.6** Create migration: `workshops` and `workshop_attendees` tables
- [x] **1.7** Create migration: `surveys` and `survey_responses` tables
- [x] **1.8** Create migration: `evaluation_documents` table
- [x] **1.9** Create migration: `requirements` table
- [x] **1.10** Create migration: `evaluation_criteria` and `requirement_criteria` tables
- [x] **1.11** Create migration: `vendors` and `vendor_contacts` tables
- [x] **1.12** Create migration: `vendor_questions`, `vendor_responses`, `vendor_documents` tables
- [x] **1.13** Create migration: `evidence` and `evidence_links` tables
- [x] **1.14** Create migration: `scores` and `score_evidence` tables
- [x] **1.15** Create migration: `consensus_scores` and `consensus_score_sources` tables
- [x] **1.16** Create migration: `ai_tasks` and `evaluation_audit_log` tables
- [x] **1.17** Create migration: RLS policies for all tables
- [x] **1.18** Create migration: Seed test data
- [x] **1.19** Push migrations and verify in Supabase dashboard

#### Checkpoint: PHASE-1-COMPLETE

```
‚òë All tables created and visible in Supabase
‚òë RLS policies applied
‚òë Test data seeded
‚òë Can query tables via Supabase MCP
```

**‚úÖ PHASE 1 COMPLETE** - Database foundation established (2026-01-01)

---

### Phase 2: Core Infrastructure

**Objective:** Create contexts, hooks, and base services

**Estimated Effort:** 1-2 sessions

#### Tasks

- [x] **2.1** Create `src/services/evaluator/` directory structure
- [x] **2.2** Create `base.evaluator.service.js` extending BaseService
- [x] **2.3** Create `evaluationProjects.service.js`
- [x] **2.4** Create `src/contexts/EvaluationContext.jsx`
- [x] **2.5** Create `src/hooks/useEvaluatorPermissions.js`
- [x] **2.6** Create `src/hooks/useEvaluationRole.js`
- [x] **2.7** Update `App.jsx` to include EvaluationProvider
- [x] **2.8** Create basic routing structure for evaluator pages
- [x] **2.9** Create `src/pages/evaluator/` directory
- [x] **2.10** Create shell `EvaluatorDashboard.jsx` page
- [x] **2.11** Create `EvaluationSwitcher.jsx` component
- [x] **2.12** Add Evaluator to main navigation (for appropriate roles)
- [ ] **2.13** Verify context works - can switch evaluations, see role

#### Checkpoint: PHASE-2-COMPLETE

```
‚òë Can navigate to /evaluator/dashboard
‚òë EvaluationContext provides current evaluation
‚òë Can switch between evaluations (if multiple exist)
‚òë Permissions hook returns correct permissions for role
‚òë Build compiles successfully
‚ñ° Manual testing pending
```

**‚úÖ PHASE 2 COMPLETE** - Core infrastructure implemented (2026-01-01)

---

### Phase 3: Requirements Module

**Objective:** Full requirements management functionality

**Estimated Effort:** 2-3 sessions

#### Session 3A: Requirements Service & List

- [x] **3A.1** Create `requirements.service.js` with full CRUD
- [x] **3A.2** Create `stakeholderAreas.service.js`
- [x] **3A.3** Create `evaluationCategories.service.js`
- [x] **3A.4** Create `RequirementsHub.jsx` page
- [x] **3A.5** Create `RequirementFilters.jsx` component
- [x] **3A.6** Create requirements list view with DataTable
- [x] **3A.7** Implement filtering by category, area, priority, status

**Mini-checkpoint 3A:**
```
‚òë Can view list of requirements
‚òë Filters work correctly
‚òë Shows category, stakeholder area, priority, status
```

#### Session 3B: Requirements CRUD

- [x] **3B.1** Create `RequirementForm.jsx` component (add/edit modal)
- [x] **3B.2** Implement create requirement with auto-generated reference code
- [x] **3B.3** Implement edit requirement
- [x] **3B.4** Implement delete requirement (soft delete)
- [x] **3B.5** Implement status workflow (draft ‚Üí review ‚Üí approved)
- [x] **3B.6** Create `RequirementCard.jsx` for detail view
- [x] **3B.7** Implement requirement validation/approval flow

**Mini-checkpoint 3B:**
```
‚òë Can create new requirements
‚òë Can edit requirements
‚òë Can delete requirements
‚òë Status transitions work
‚òë Approval workflow works
```

#### Session 3C: Requirements Matrix & Settings

- [x] **3C.1** Create `RequirementMatrix.jsx` component (grid view)
- [x] **3C.2** Implement grouping by category/area/priority
- [x] **3C.3** Create stakeholder areas management UI
- [x] **3C.4** Create evaluation categories management UI (with weights)
- [x] **3C.5** Create scoring scale configuration UI
- [x] **3C.6** Add requirements count to dashboard

#### Checkpoint: PHASE-3-COMPLETE

```
‚òë Full requirements CRUD working
‚òë Matrix view displays requirements grouped
‚òë Can manage stakeholder areas
‚òë Can manage evaluation categories with weights
‚òë Weights sum to 100% validation
‚òë Scoring scale configured
```

**‚úÖ PHASE 3 COMPLETE** - Requirements Module fully implemented (2026-01-01)

---

### Phase 4: Input Capture

**Objective:** Workshops, surveys, and document upload

**Estimated Effort:** 2-3 sessions

#### Session 4A: Workshops

- [x] **4A.1** Create `workshops.service.js`
- [x] **4A.2** Create `WorkshopsHub.jsx` page
- [x] **4A.3** Create `WorkshopCard.jsx` component
- [x] **4A.4** Implement workshop CRUD (schedule, edit, delete)
- [x] **4A.5** Implement attendee management
- [x] **4A.6** Create `WorkshopCapture.jsx` - live requirement capture mode
- [x] **4A.7** Link captured requirements to workshop + attendee

**Mini-checkpoint 4A:**
```
‚òë Can create/edit/delete workshops
‚òë Can manage attendees
‚òë Live capture mode works
‚òë Requirements linked to workshop source
```

#### Session 4B: Surveys & Follow-up

- [x] **4B.1** Create `surveys.service.js`
- [x] **4B.2** Create simple survey builder (question types: text, choice, rating)
- [x] **4B.3** Create `WorkshopFollowup.jsx` - post-workshop validation form
- [x] **4B.4** Implement "Share with attendees" functionality
- [x] **4B.5** Create survey response capture
- [x] **4B.6** Allow adding requirements from survey responses

**Mini-checkpoint 4B:**
```
‚òë Can create post-workshop surveys
‚òë Can send to attendees (via ShareWithAttendees modal)
‚òë Can capture responses
‚òë Requirements from surveys linked correctly
```

#### Session 4C: Document Upload

- [x] **4C.1** Create `evaluationDocuments.service.js`
- [x] **4C.2** Implement file upload to Supabase Storage
- [x] **4C.3** Create document list view
- [x] **4C.4** Create document viewer/preview
- [x] **4C.5** Placeholder for AI parsing (implemented in Phase 8)

#### Checkpoint: PHASE-4-COMPLETE

```
‚òë Workshop management complete
‚òë Live capture mode functional
‚òë Post-workshop follow-up surveys work
‚òë Document upload works
‚òë All inputs link to requirements with provenance
```

**üõë STOP HERE** - Report completion, demonstrate input capture, ask to proceed to Phase 5

---

### Phase 5: Vendor Management

**Objective:** Vendor pipeline and basic portal

**Estimated Effort:** 2 sessions

#### Session 5A: Vendor CRUD & Pipeline

- [x] **5A.1** Create `vendors.service.js`
- [x] **5A.2** Create `VendorsHub.jsx` page
- [x] **5A.3** Create `VendorPipeline.jsx` - Kanban-style status view
- [x] **5A.4** Create `VendorCard.jsx` component
- [x] **5A.5** Implement vendor CRUD
- [x] **5A.6** Implement status transitions with history
- [x] **5A.7** Create `VendorDetail.jsx` page
- [x] **5A.8** Implement vendor contacts management

**Mini-checkpoint 5A:**
```
‚òë Can create/edit/delete vendors
‚òë Pipeline view shows vendors by status
‚òë Can move vendors through pipeline
‚òë Vendor detail page works
```

#### Session 5B: Questions & Portal Setup

- [x] **5B.1** Create `vendorQuestions.service.js`
- [x] **5B.2** Create question management UI
- [x] **5B.3** Link questions to requirements/criteria
- [x] **5B.4** Implement portal access code generation
- [x] **5B.5** Create `api/evaluator/vendor-portal-auth.js`
- [x] **5B.6** Create basic `VendorPortal.jsx` page (shell)
- [x] **5B.7** Create `VendorResponseForm.jsx` component

#### Checkpoint: PHASE-5-COMPLETE

```
‚òë Vendor pipeline management works
‚òë Can manage vendor questions
‚òë Portal access codes generated
‚òë Basic vendor portal authenticates
‚òë Vendors can view questions (responses in Phase 6)
```

**‚úÖ PHASE 5 COMPLETE** - Vendor Management fully implemented (2026-01-03)

---

### Phase 6: Evaluation & Scoring

**Objective:** Scoring interface, evidence management, reconciliation

**Estimated Effort:** 2-3 sessions

#### Session 6A: Evidence Management

- [x] **6A.1** Create `evidence.service.js`
- [x] **6A.2** Create evidence capture UI (demo notes, reference checks)
- [x] **6A.3** Link evidence to vendors
- [x] **6A.4** Link evidence to requirements/criteria
- [x] **6A.5** Create evidence list view on vendor detail page

**Mini-checkpoint 6A:**
```
‚òë Can add evidence for vendors
‚òë Evidence linked to requirements/criteria
‚òë Evidence displays on vendor detail
```

#### Session 6B: Scoring Interface

- [x] **6B.1** Create `scores.service.js`
- [x] **6B.2** Create `EvaluationHub.jsx` page
- [x] **6B.3** Create `ScoringInterface.jsx` component
- [x] **6B.4** Implement score entry with rationale
- [x] **6B.5** Link evidence to scores
- [x] **6B.6** Create `ScoreCard.jsx` component
- [x] **6B.7** Show vendor response and evidence when scoring

**Mini-checkpoint 6B:**
```
‚òë Can score vendors against criteria
‚òë Scores require rationale
‚òë Can link evidence to scores
‚òë Shows relevant context when scoring
```

#### Session 6C: Vendor Responses & Reconciliation

- [x] **6C.1** Complete vendor portal response submission
- [x] **6C.2** Create vendor document upload in portal
- [x] **6C.3** Create `ReconciliationPanel.jsx` component
- [x] **6C.4** Show multiple evaluator scores side-by-side
- [x] **6C.5** Implement consensus score entry
- [x] **6C.6** Calculate weighted totals

#### Checkpoint: PHASE-6-COMPLETE

```
‚òë Vendors can submit responses via portal
‚òë Vendors can upload documents
‚òë Evaluators can score with evidence
‚òë Reconciliation shows evaluator variance
‚òë Consensus scores can be entered
‚òë Weighted totals calculate correctly
```

**‚úÖ PHASE 6 COMPLETE** - Evaluation & Scoring fully implemented (2026-01-04)

---


### Phase 7: Traceability & Reports

**Objective:** Traceability matrix, client dashboard, report generation

**Estimated Effort:** 2 sessions

#### Session 7A: Traceability Matrix

- [x] **7A.1** Create `traceability.service.js` with complex queries
- [x] **7A.2** Create `TraceabilityView.jsx` page
- [x] **7A.3** Create `TraceabilityMatrix.jsx` component
- [x] **7A.4** Implement matrix: requirements (rows) √ó vendors (columns)
- [x] **7A.5** Show scores in cells with visual indicators
- [x] **7A.6** Create `TraceabilityDrilldown.jsx` modal
- [x] **7A.7** Show full chain: requirement ‚Üí evidence ‚Üí score ‚Üí rationale
- [x] **7A.8** Add grouping by category

**Mini-checkpoint 7A:**
```
‚òë Matrix displays all requirements vs vendors
‚òë Scores visible with RAG styling
‚òë Can drill down to see full traceability
‚òë Grouping by category works
```

#### Session 7B: Client Dashboard & Reports

- [ ] **7B.1** Create `ClientPortal.jsx` page
- [ ] **7B.2** Create client authentication flow (access code based)
- [ ] **7B.3** Create `ClientDashboard.jsx` component
- [ ] **7B.4** Show progress summary
- [ ] **7B.5** Show requirements summary (contributed, approved)
- [ ] **7B.6** Show vendor comparison (if allowed)
- [ ] **7B.7** Create `ReportsHub.jsx` page
- [ ] **7B.8** Create `api/evaluator/generate-report.js`
- [ ] **7B.9** Implement PDF export of evaluation report
- [ ] **7B.10** Implement CSV export of requirements/scores

#### Checkpoint: PHASE-7-COMPLETE

```
‚ñ° Traceability matrix fully functional
‚ñ° Drill-down shows complete chain
‚ñ° Client portal authenticates and shows dashboard
‚ñ° Progress visible to clients
‚ñ° PDF report generates
‚ñ° CSV exports work
```

**üõë STOP HERE** - Report completion, demonstrate traceability and reports, ask to proceed to Phase 8

---

### Phase 8: AI Features

**Objective:** AI-powered analysis and suggestions

**Estimated Effort:** 2 sessions

#### Session 8A: Document Parsing & Gap Analysis

- [ ] **8A.1** Create `api/evaluator/ai-document-parse.js`
- [ ] **8A.2** Implement document parsing for requirements extraction
- [ ] **8A.3** Create UI for reviewing parsed requirements
- [ ] **8A.4** Allow importing parsed requirements
- [ ] **8A.5** Create `api/evaluator/ai-gap-analysis.js`
- [ ] **8A.6** Create `GapAnalysisResults.jsx` component
- [ ] **8A.7** Show suggested requirements from gap analysis
- [ ] **8A.8** Allow adding AI suggestions to requirements

**Mini-checkpoint 8A:**
```
‚ñ° Can upload document and extract requirements
‚ñ° Review and import flow works
‚ñ° Gap analysis identifies missing areas
‚ñ° Can add suggestions to requirements
```

#### Session 8B: Market Research & AI Assistant

- [ ] **8B.1** Create `api/evaluator/ai-market-research.js`
- [ ] **8B.2** Create `MarketResearchResults.jsx` component
- [ ] **8B.3** Allow adding researched vendors to long list
- [ ] **8B.4** Create `api/evaluator/ai-requirement-suggest.js`
- [ ] **8B.5** Implement requirement language improvement
- [ ] **8B.6** Create `AIAssistantPanel.jsx` sidebar
- [ ] **8B.7** Integrate AI functions into main UI

#### Checkpoint: PHASE-8-COMPLETE

```
‚ñ° Document parsing extracts requirements
‚ñ° Gap analysis suggests missing requirements
‚ñ° Market research returns vendor information
‚ñ° AI assistant panel accessible
‚ñ° All AI tasks logged to ai_tasks table
```

**üõë STOP HERE** - Report completion, demonstrate AI features, ask to proceed to Phase 9

---

### Phase 9: Portal Refinement

**Objective:** Polish client and vendor portals

**Estimated Effort:** 1-2 sessions

#### Tasks

- [ ] **9.1** Refine client portal branding (use evaluation project branding)
- [ ] **9.2** Add client requirement approval workflow
- [ ] **9.3** Add client comments/feedback on requirements
- [ ] **9.4** Improve vendor portal UX
- [ ] **9.5** Add vendor response progress tracking
- [ ] **9.6** Add vendor document categorization
- [ ] **9.7** Email notification placeholders (for portal access)
- [ ] **9.8** Session timeout handling for portals
- [ ] **9.9** Mobile responsiveness for portals

#### Checkpoint: PHASE-9-COMPLETE

```
‚ñ° Client portal fully branded
‚ñ° Client can approve/comment on requirements
‚ñ° Vendor portal polished and functional
‚ñ° Progress tracking works
‚ñ° Portals work on mobile
```

**üõë STOP HERE** - Report completion, demonstrate polished portals, ask to proceed to Phase 10

---

### Phase 10: Testing & Polish

**Objective:** Full testing, bug fixes, documentation

**Estimated Effort:** 2-3 sessions

#### Session 10A: E2E Tests

- [ ] **10A.1** Create `e2e/evaluator/` directory
- [ ] **10A.2** Create `evaluator-admin.spec.js` - full admin workflow
- [ ] **10A.3** Create `evaluator-evaluator.spec.js` - evaluator workflow
- [ ] **10A.4** Create `evaluator-client.spec.js` - client portal tests
- [ ] **10A.5** Create `evaluator-vendor-portal.spec.js` - vendor portal tests
- [ ] **10A.6** Run all tests, fix failures

**Mini-checkpoint 10A:**
```
‚ñ° All E2E tests pass
‚ñ° No console errors during tests
```

#### Session 10B: Unit Tests & Bug Fixes

- [ ] **10B.1** Add unit tests for services
- [ ] **10B.2** Add unit tests for permission functions
- [ ] **10B.3** Add unit tests for calculations (weights, totals)
- [ ] **10B.4** Fix any bugs found during testing
- [ ] **10B.5** Performance review and optimization

#### Session 10C: Documentation & Handoff

- [ ] **10C.1** Update APPLICATION-CONTEXT.md with Evaluator section
- [ ] **10C.2** Create user documentation / help content
- [ ] **10C.3** Review and update EVALUATOR-TECHNICAL-ARCHITECTURE.md
- [ ] **10C.4** Final code review and cleanup
- [ ] **10C.5** Create release notes

#### Checkpoint: PHASE-10-COMPLETE (FINAL)

```
‚ñ° All tests passing
‚ñ° No known bugs
‚ñ° Documentation complete
‚ñ° Ready for production use
```

**üéâ IMPLEMENTATION COMPLETE**

---

## Part 5: Session Handoff Protocol

### Starting a New Session

When starting a new AI chat session for Evaluator development:

1. **Share Context Documents:**
   ```
   Please read these documents to understand the project:
   - docs/EVALUATOR-IMPLEMENTATION-PLAN.md (this document)
   - docs/APPLICATION-CONTEXT.md
   - docs/EVALUATOR-TECHNICAL-ARCHITECTURE.md
   ```

2. **State Current Position:**
   ```
   We are currently at [CHECKPOINT NAME].
   The last completed task was [TASK NUMBER].
   Please continue with [NEXT TASK].
   ```

3. **Provide Any Session-Specific Context:**
   ```
   In the last session, we encountered [ISSUE] and decided [DECISION].
   ```

### Ending a Session

Before ending an AI chat session:

1. **Update Progress Tracker** at top of this document
2. **Update Last Checkpoint Completed** section
3. **Note any decisions made** that affect future work
4. **Note any issues encountered** that need resolution
5. **Commit all changes** to git

### Example Session Start Prompt

```
I'm continuing work on the Evaluator tool for AMSF001 Project Tracker.

Please read these files to get context:
1. ~/Projects/amsf001-project-tracker/docs/EVALUATOR-IMPLEMENTATION-PLAN.md
2. ~/Projects/amsf001-project-tracker/docs/APPLICATION-CONTEXT.md

Current status: Phase 3 (Requirements Module), task 3B.3 complete.
Next task: 3B.4 - Implement delete requirement (soft delete)

Please continue implementation.
```

---

## Part 6: Decision Log

Track important decisions made during implementation.

| Date | Decision | Rationale | Impact |
|------|----------|-----------|--------|
| 2026-01-01 | EvaluationProject parallel to Project | Clean separation, independent lifecycle | Separate context provider needed |
| 2026-01-01 | Vendor portal uses access codes not accounts | Lower barrier for vendor participation | Separate auth flow needed |
| | | | |

---

## Part 7: Issue Tracker

Track issues encountered and their resolution.

| ID | Issue | Status | Resolution |
|----|-------|--------|------------|
| | | | |

---

## Part 8: File Reference

Quick reference for key files created during implementation.

### Database Migrations
```
supabase/migrations/
‚îú‚îÄ‚îÄ [timestamp]_create_evaluation_projects.sql
‚îú‚îÄ‚îÄ [timestamp]_create_stakeholder_areas.sql
‚îú‚îÄ‚îÄ ... (filled in as created)
```

### Services
```
src/services/evaluator/
‚îú‚îÄ‚îÄ index.js
‚îú‚îÄ‚îÄ base.evaluator.service.js
‚îú‚îÄ‚îÄ evaluationProjects.service.js
‚îú‚îÄ‚îÄ requirements.service.js
‚îú‚îÄ‚îÄ ... (filled in as created)
```

### Contexts & Hooks
```
src/contexts/EvaluationContext.jsx
src/hooks/useEvaluatorPermissions.js
src/hooks/useEvaluationRole.js
```

### Pages
```
src/pages/evaluator/
‚îú‚îÄ‚îÄ EvaluatorDashboard.jsx
‚îú‚îÄ‚îÄ RequirementsHub.jsx
‚îú‚îÄ‚îÄ ... (filled in as created)
```

### Components
```
src/components/evaluator/
‚îú‚îÄ‚îÄ index.js
‚îú‚îÄ‚îÄ EvaluationSwitcher.jsx
‚îú‚îÄ‚îÄ requirements/
‚îú‚îÄ‚îÄ workshops/
‚îú‚îÄ‚îÄ ... (filled in as created)
```

### API Endpoints
```
api/evaluator/
‚îú‚îÄ‚îÄ vendor-portal-auth.js
‚îú‚îÄ‚îÄ ai-gap-analysis.js
‚îú‚îÄ‚îÄ ... (filled in as created)
```

---

*Document Version: 1.0*
*Created: 2026-01-01*
*Last Updated: 2026-01-01*

